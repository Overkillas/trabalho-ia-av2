{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b86799c3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbe2cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edeae2f",
   "metadata": {},
   "source": [
    "## Preparar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6fbc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"../data/spiral_d.csv\", delimiter=\",\")\n",
    "X = data[:, :2].T   # 2 x N\n",
    "y = data[:, 2]      # N\n",
    "y = np.where(y==1, 1, -1)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7515222",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(X[0, y==1], X[1, y==1], marker='s', color='r', label='Classe 1')\n",
    "plt.scatter(X[0, y==-1], X[1, y==-1], marker='o', color='b', label='Classe -1')\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.title(\"Distribuição dos dados\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3d2004",
   "metadata": {},
   "source": [
    "#### Separando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6856fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Particionamento 80% treino, 20% teste\n",
    "N = X.shape[1]\n",
    "indices = np.arange(N)\n",
    "np.random.shuffle(indices)\n",
    "N_train = int(0.8*N)\n",
    "train_idx = indices[:N_train]\n",
    "test_idx  = indices[N_train:]\n",
    "\n",
    "X_train = X[:, train_idx]\n",
    "y_train = y[train_idx]\n",
    "\n",
    "X_test  = X[:, test_idx]\n",
    "y_test  = y[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acbca17",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5c43c",
   "metadata": {},
   "source": [
    "### Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77797fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap da matriz de confusão\n",
    "def show_classification_results(model_name, cm, acc, sensitivity, specificity, precision, f1):\n",
    "    print(f\"{model_name} - Resultados da Classificação:\")\n",
    "    print(\"\\nMatriz de Confusão (formato solicitado):\")\n",
    "    print(cm)\n",
    "    print(f\"\\nAcurácia: {acc:.3f}\")\n",
    "    print(f\"Sensibilidade (Recall da classe positiva): {sensitivity:.3f}\")\n",
    "    print(f\"Especificidade (Recall da classe negativa): {specificity:.3f}\")\n",
    "    print(f\"Precisão: {precision:.3f}\")\n",
    "    print(f\"F1 Score: {f1:.3f}\\n\")\n",
    "    \n",
    "    # Heatmap da matriz de confusão\n",
    "    plt.figure(figsize=(5,4))\n",
    "    \n",
    "    # MUDANÇA AQUI: Os rótulos de X (xticklabels) foram ajustados\n",
    "    # para corresponder à sua nova matriz [Prev=1, Prev=-1]\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "                xticklabels=[\"Positivo (1)\", \"Negativo (-1)\"],\n",
    "                yticklabels=[\"Positivo (1)\", \"Negativo (-1)\"])\n",
    "    \n",
    "    plt.xlabel(\"Classe Prevista\")\n",
    "    plt.ylabel(\"Classe Verdadeira\")\n",
    "    plt.title(f\"Matriz de Confusão - {model_name}\")\n",
    "    plt.show()\n",
    "\n",
    "# Matrizes de confusão (manual)\n",
    "def confusion_matrix_manual(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Cria a matriz de confusão com base na definição do usuário:\n",
    "    TP (1, 1)  FP (1, -1)\n",
    "    TN (-1, 1) FN (-1, -1)\n",
    "    \"\"\"\n",
    "    # Definições Padrão\n",
    "    TP_std = np.sum((y_true==1) & (y_pred==1))    # Real=1, Prev=1\n",
    "    FN_std = np.sum((y_true==1) & (y_pred==-1))   # Real=1, Prev=-1\n",
    "    FP_std = np.sum((y_true==-1) & (y_pred==1))   # Real=-1, Prev=1\n",
    "    TN_std = np.sum((y_true==-1) & (y_pred==-1))   # Real=-1, Prev=-1\n",
    "    \n",
    "    # Mapeando para a estrutura solicitada pelo usuário\n",
    "    TP = TP_std  # (1, 1)\n",
    "    FP = FN_std  # (1, -1) -> Este é o Falso Negativo padrão\n",
    "    TN = FP_std  # (-1, 1) -> Este é o Falso Positivo padrão\n",
    "    FN = TN_std  # (-1, -1) -> Este é o Verdadeiro Negativo padrão\n",
    "    \n",
    "    # Retorna a matriz na estrutura [[TP, FP], [TN, FN]]\n",
    "    return np.array([[TP, FP],\n",
    "                     [TN, FN]])\n",
    "\n",
    "# Métricas\n",
    "def metrics(cm):\n",
    "    \"\"\"\n",
    "    Calcula métricas a partir da matriz não-padrão:\n",
    "    cm = [[TP_usr, FP_usr],\n",
    "          [TN_usr, FN_usr]]\n",
    "    \"\"\"\n",
    "    # Desempacota a matriz do usuário\n",
    "    TP_usr, FP_usr = cm[0]\n",
    "    TN_usr, FN_usr = cm[1]\n",
    "    \n",
    "    # Mapeia de volta para as definições padrão para cálculo\n",
    "    TP = TP_usr  # (Real=1, Prev=1)\n",
    "    FN = FP_usr  # (Real=1, Prev=-1)\n",
    "    FP = TN_usr  # (Real=-1, Prev=1)\n",
    "    TN = FN_usr  # (Real=-1, Prev=-1)\n",
    "\n",
    "    # Calcula métricas usando as fórmulas padrão\n",
    "    Total = TP + TN + FP + FN\n",
    "    acc = (TP+TN) / Total if Total != 0 else 0\n",
    "    sens = TP/(TP+FN) if (TP+FN)!=0 else 0\n",
    "    spec = TN/(TN+FP) if (TN+FP)!=0 else 0\n",
    "    prec = TP/(TP+FP) if (TP+FP)!=0 else 0\n",
    "    f1 = 2*prec*sens/(prec+sens) if (prec+sens)!=0 else 0\n",
    "    \n",
    "    return acc, sens, spec, prec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63e3e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, X_train, y_train, learning_rate=1e-3, plot=True, max_epochs=1000):\n",
    "        self.p, self.N = X_train.shape\n",
    "        self.X_train = np.vstack((\n",
    "            -np.ones((1, self.N)), X_train\n",
    "        ))\n",
    "        self.d = y_train\n",
    "        self.lr = learning_rate\n",
    "        self.w = np.random.random_sample((self.p+1,1)) - 0.5\n",
    "        self.plot = plot\n",
    "        self.max_epochs = max_epochs\n",
    "        self.x1 = np.linspace(-2, 10)\n",
    "        \n",
    "        if plot:\n",
    "            self.fig = plt.figure(1)\n",
    "            self.ax = self.fig.add_subplot()\n",
    "            self.ax.scatter(self.X_train[1, self.d[:]==1],\n",
    "                            self.X_train[2, self.d[:]==1], marker='s', s=120)\n",
    "            self.ax.scatter(self.X_train[1, self.d[:]==-1],\n",
    "                            self.X_train[2, self.d[:]==-1], marker='o', s=120)\n",
    "            self.ax.set_xlim(-1, 7)\n",
    "            self.ax.set_ylim(-1, 7)\n",
    "            self.draw_line()\n",
    "        \n",
    "    def draw_line(self, c='k', alpha=1, lw=2):\n",
    "        x2 = -self.w[1,0]/self.w[2,0]*self.x1 + self.w[0,0]/self.w[2,0]\n",
    "        x2 = np.nan_to_num(x2)\n",
    "        if self.plot:\n",
    "            plt.plot(self.x1, x2, c=c, alpha=alpha, lw=lw)\n",
    "        \n",
    "    def activation_function(self, u):\n",
    "        return 1 if u >= 0 else -1\n",
    "    \n",
    "    def fit(self):\n",
    "        epochs = 0\n",
    "        error = True\n",
    "        while error and epochs < self.max_epochs:\n",
    "            error = False\n",
    "            for k in range(self.N):\n",
    "                x_k = self.X_train[:, k].reshape(self.p+1, 1)\n",
    "                u_k = (self.w.T @ x_k)[0,0]\n",
    "                y_k = self.activation_function(u_k)\n",
    "                d_k = self.d[k]\n",
    "                e_k = d_k - y_k\n",
    "                if e_k != 0:\n",
    "                    error = True\n",
    "                self.w = self.w + self.lr * e_k * x_k\n",
    "            \n",
    "            if self.plot:\n",
    "                plt.pause(.4)\n",
    "                self.draw_line(c='r', alpha=.5)\n",
    "            epochs += 1\n",
    "        \n",
    "        if self.plot:\n",
    "            plt.pause(.4)\n",
    "            self.draw_line(c='g', alpha=1, lw=4)\n",
    "            plt.show()\n",
    "\n",
    "        plt.figure(figsize=(6,5))\n",
    "        plt.scatter(self.X_train[1, self.d[:]==1], self.X_train[2, self.d[:]==1], marker='s', s=120, label='Classe 1')\n",
    "        plt.scatter(self.X_train[1, self.d[:]==-1], self.X_train[2, self.d[:]==-1], marker='o', s=120, label='Classe -1')\n",
    "        min_x1 = self.X_train[1, :].min() - 1  # Adiciona uma margem\n",
    "        max_x1 = self.X_train[1, :].max() + 1  # Adiciona uma margem\n",
    "        x1 = np.linspace(min_x1, max_x1)\n",
    "        x2 = -self.w[1,0]/self.w[2,0]*x1 + self.w[0,0]/self.w[2,0]\n",
    "        x2 = np.nan_to_num(x2)\n",
    "        plt.plot(x1, x2, c='g', lw=4, label='Linha de decisão final')\n",
    "        plt.xlabel(\"x1\")\n",
    "        plt.ylabel(\"x2\")\n",
    "        plt.title(f\"Perceptron - Última época ({epochs})\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        if epochs == self.max_epochs:\n",
    "            misclassified = [k for k in range(self.N) \n",
    "            if self.activation_function((self.w.T @ self.X_train[:, k].reshape(self.p+1,1))[0,0]) != self.d[k]]\n",
    "            print(f'Treinamento interrompido após {epochs} épocas (não convergiu completamente).')\n",
    "            print(\"Índices dos exemplos incorretos:\", misclassified)\n",
    "            print(\"Pesos finais:\", self.w.ravel())\n",
    "        else:\n",
    "            print(f'Treinamento concluído em {epochs} épocas.')\n",
    "\n",
    "    def predict(self, X):\n",
    "        N = X.shape[1]\n",
    "        y_pred = np.zeros(N)\n",
    "        for i in range(N):\n",
    "            x_i = np.vstack((-np.ones((1,1)), X[:,i].reshape(-1,1)))\n",
    "            y_pred[i] = self.activation_function((self.w.T @ x_i)[0,0])\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a5125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron:\n",
    "    def __init__(self,X_train:np.ndarray, Y_train:np.ndarray, topology:list, learning_rate = 1e-3, max_epoch=10000, tol = 1e-12):\n",
    "        '''\n",
    "        X_train (p x N)\n",
    "        Y_train (C x N) ou (1 x N) se classificação binária\n",
    "        '''\n",
    "        self.p , self.N = X_train.shape\n",
    "        self.m = Y_train.shape[0]\n",
    "        \n",
    "        self.X_train = np.vstack((\n",
    "            -np.ones((1,self.N)),X_train\n",
    "        ))\n",
    "        self.tol = tol\n",
    "        self.lr = learning_rate\n",
    "        self.d = Y_train\n",
    "        topology.append(self.m)\n",
    "        self.W = [None]*len(topology)\n",
    "        Z = 0\n",
    "        for i in range(len(self.W)):\n",
    "            if i == 0:\n",
    "                W = np.random.random_sample((topology[i],self.p+1))-.5\n",
    "            else:\n",
    "                W = np.random.random_sample((topology[i],topology[i-1]+1))-.5\n",
    "            self.W[i] = W\n",
    "            Z += W.size\n",
    "        print(f\"Rede MLP com {Z} parâmetros\")\n",
    "        self.max_epoch = max_epoch\n",
    "        self.y = [None]*len(topology)\n",
    "        self.u = [None]*len(topology)\n",
    "        self.delta = [None]*len(topology)\n",
    "        \n",
    "    def g(self, u):\n",
    "        return (1-np.exp(-u))/(1+np.exp(-u))\n",
    "    \n",
    "    def g_d(self, u):\n",
    "        y = self.g(u)\n",
    "        return .5*(1-y**2)\n",
    "    \n",
    "    def backward(self, e,x):\n",
    "        for i in range(len(self.W)-1,-1,-1):\n",
    "            if i == len(self.W)-1:\n",
    "                self.delta[i] = self.g_d(self.u[i]) * e\n",
    "                yb = np.vstack((\n",
    "                    -np.ones((1,1)),\n",
    "                    self.y[i-1]\n",
    "                ))\n",
    "                self.W[i] = self.W[i] + self.lr*(self.delta[i]@yb.T)\n",
    "            elif i == 0:\n",
    "                Wnbt = (self.W[i+1][:,1:]).T\n",
    "                self.delta[i] = self.g_d(self.u[i]) * (Wnbt@self.delta[i+1])\n",
    "                self.W[i] = self.W[i] + self.lr*(self.delta[i]@x.T)\n",
    "                \n",
    "            else:\n",
    "                Wnbt = (self.W[i+1][:,1:]).T\n",
    "                self.delta[i] = self.g_d(self.u[i]) * (Wnbt@self.delta[i+1])\n",
    "                yb = np.vstack((\n",
    "                    -np.ones((1,1)),\n",
    "                    self.y[i-1]\n",
    "                ))\n",
    "                self.W[i] = self.W[i] + self.lr*(self.delta[i]@yb.T)\n",
    "            \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        for i,W in enumerate(self.W):\n",
    "            if i == 0:\n",
    "                self.u[i] = W@x\n",
    "            else:\n",
    "                yb = np.vstack((\n",
    "                    -np.ones((1,1)), self.y[i-1]\n",
    "                ))\n",
    "                self.u[i] = W@yb                \n",
    "            self.y[i] = self.g(self.u[i])\n",
    "         \n",
    "        \n",
    "        \n",
    "    def EQM(self):\n",
    "        s = 0\n",
    "        for k in range(self.N):\n",
    "            x_k = self.X_train[:,k].reshape(self.p+1,1)\n",
    "            self.forward(x_k)\n",
    "            y = self.y[-1]\n",
    "            d = self.d[:,k].reshape(self.m,1)\n",
    "            e = d - y\n",
    "            s += np.sum(e**2)\n",
    "        return s/(2*self.N)\n",
    "        \n",
    "    def fit(self):\n",
    "        epoch = 0\n",
    "        EQM1 = 1\n",
    "        self.history = []\n",
    "        \n",
    "        while epoch < self.max_epoch and EQM1>self.tol:\n",
    "            t1 = time()\n",
    "            for k in range(self.N):\n",
    "                x_k = self.X_train[:,k].reshape(self.p+1,1)\n",
    "                #Forward\n",
    "                self.forward(x_k)\n",
    "                y = self.y[-1]\n",
    "                d = self.d[:,k].reshape(self.m,1)\n",
    "                e = d - y\n",
    "                #Backward\n",
    "                self.backward(e,x_k)\n",
    "            t2 = time()\n",
    "            EQM1 = self.EQM()\n",
    "            self.history.append(EQM1)\n",
    "            epoch+=1\n",
    "            print(f\"Tempo: {t2-t1:.5f}s  Época: {epoch}, EQM: {EQM1:.15f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Faz a predição para novos dados X (p x N_test)\n",
    "        Retorna uma matriz de saída (m x N_test)\n",
    "        \"\"\"\n",
    "        N_test = X.shape[1]\n",
    "\n",
    "        X_bias = np.vstack((-np.ones((1, N_test)), X))\n",
    "        \n",
    "        Y_pred = np.zeros((self.m, N_test))\n",
    "        \n",
    "        for k in range(N_test):\n",
    "            x_k = X_bias[:, k].reshape(self.p+1, 1)\n",
    "            self.forward(x_k)\n",
    "            Y_pred[:, k] = self.y[-1][:, 0]\n",
    "        \n",
    "        return Y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be2ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Perceptron(X_train=X_train, y_train=y_train, learning_rate=0.01, plot=False, max_epochs=500)\n",
    "perceptron.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109c7d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = perceptron.predict(X_train)\n",
    "y_pred_test  = perceptron.predict(X_test)\n",
    "\n",
    "cm_train = confusion_matrix_manual(y_train, y_pred_train)\n",
    "cm_test  = confusion_matrix_manual(y_test, y_pred_test)\n",
    "\n",
    "acc_train, sens_train, spec_train, prec_train, f1_train = metrics(cm_train)\n",
    "acc_test, sens_test, spec_test, prec_test, f1_test = metrics(cm_test)\n",
    "\n",
    "# Matrizes de confusão\n",
    "cm_train = confusion_matrix_manual(y_train, y_pred_train)\n",
    "cm_test  = confusion_matrix_manual(y_test, y_pred_test)\n",
    "\n",
    "# Métricas\n",
    "acc_train, sens_train, spec_train, prec_train, f1_train = metrics(cm_train)\n",
    "acc_test, sens_test, spec_test, prec_test, f1_test = metrics(cm_test)\n",
    "\n",
    "# Exibição dos resultados\n",
    "show_classification_results(\"Perceptron - Treino\", cm_train, acc_train, sens_train, spec_train, prec_train, f1_train)\n",
    "show_classification_results(\"Perceptron - Teste\",  cm_test,  acc_test,  sens_test,  spec_test,  prec_test,  f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeb661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar labels para MLP (1 x N)\n",
    "Y_train_mlp = y_train.reshape(1, -1)\n",
    "Y_test_mlp  = y_test.reshape(1, -1)\n",
    "\n",
    "# Criar MLP (topologia: camada oculta com 5 neurônios)\n",
    "mlp = MultilayerPerceptron(X_train=X_train, Y_train=Y_train_mlp, topology=[5], learning_rate=0.01, max_epoch=500)\n",
    "mlp.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0951803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predição\n",
    "Y_pred_train_raw = mlp.predict(X_train)\n",
    "Y_pred_test_raw  = mlp.predict(X_test)\n",
    "\n",
    "# Convertendo saída para {-1,1}\n",
    "y_pred_train_mlp = np.where(Y_pred_train_raw[0,:] >= 0, 1, -1)\n",
    "y_pred_test_mlp  = np.where(Y_pred_test_raw[0,:] >= 0, 1, -1)\n",
    "\n",
    "# Matrizes de confusão\n",
    "cm_train_mlp = confusion_matrix_manual(y_train, y_pred_train_mlp)\n",
    "cm_test_mlp  = confusion_matrix_manual(y_test, y_pred_test_mlp)\n",
    "\n",
    "# Métricas\n",
    "acc_train_mlp, sens_train_mlp, spec_train_mlp, prec_train_mlp, f1_train_mlp = metrics(cm_train_mlp)\n",
    "acc_test_mlp, sens_test_mlp, spec_test_mlp, prec_test_mlp, f1_test_mlp = metrics(cm_test_mlp)\n",
    "\n",
    "# Mostrar resultados com heatmap\n",
    "show_classification_results(\"MLP - Treino\", cm_train_mlp, acc_train_mlp, sens_train_mlp, spec_train_mlp, prec_train_mlp, f1_train_mlp)\n",
    "show_classification_results(\"MLP - Teste\", cm_test_mlp, acc_test_mlp, sens_test_mlp, spec_test_mlp, prec_test_mlp, f1_test_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cc01d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(mlp.history)\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"EQM\")\n",
    "plt.title(\"Curva de aprendizado MLP\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
